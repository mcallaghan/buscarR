[{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Stopping Criteria","text":"machine learning-prioritised screening systematic review, can save work method deciding stop. Several methods suggested, rely rules thumb (like stopping N consecutive irrelevant records) supported either theory empirical evaluations. particular value N may work well one review, badly another. right value depends size dataset, prevalence relevant documents, effectiveness machine learning algorithm, bit luck. Moreover, using criterion allow us say anything expected recall, confidence achieving . Callaghan Müller-Hansen (2020) offered theoretically well motivated stopping criteria, demonstrated safe use. allows communicate confidence achieving arbitrary recall target. package aims make stopping criteria easy use R users.","code":"library(buscarR)"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Stopping Criteria","text":"Lets initialise test data. demonstration purposes, define number documents, prevalence relevant documents. simulate prioritised screening-like process, sample documents, bias times likely select random relevant document random irrelevant document.","code":"N <- 60000 # number of documents prevalence <- 0.01 # prevalence of relevant documents r <- N*0.01 # number of relevant documents bias <- 10   docs <- rep(0,N) docs[1:r] <- 1 weights = rep(1,N) weights[1:r] <- bias set.seed(2023) docs <- sample(   docs, prob=weights, replace=F )  df <- data.frame(relevant=docs)  plot(   cumsum(df$relevant),   type='l',   main=\"Simulation of ML-prioritised screening\",   xlab=\"Documents seen\",   ylab=\"Relevant  documents seen\" )"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"when-is-it-safe-to-stop","dir":"Articles","previous_headings":"","what":"When is it safe to stop?","title":"Stopping Criteria","text":"Let’s imagine ’ve seen just first 20,000 documents. can use stopping criteria calculate p score null hypothesis missed many documents achieved recall target. p score low, can reject null hypothesis stop safely. lower score, confident can . p score given calculating probability observing previous sequence relevant irrelevant documents, enough remaining relevant documents mean recall target achieved. example, seen 95 relevant documents, recall target 95%, least 6 relevant documents remaining us missed target. just observed sequence 100 irrelevant document row, ask likely observe random sampling, 6 relevant documents remaining. can calculate using buscarR package, passing dataframe column relevant contains 1s 0s relevant irrelevant documents (NAs documents seen yet). separate column seen tells us document seen human yet . dataframe many rows unique documents dataset, contain seen human documents yet seen human. human-screened documents order screened.  p score 0.8418202 indicates yet confident enough stop screening. now “see” additional 10,000 documents, change.  can now confident missed recall target","code":"df$seen <- 0 df$seen[1:20000] <- 1 plot(   cumsum(df[df$seen==1,\"relevant\"]),   type='l',   main=\"Simulation of ML-prioritised screening\",   xlab=\"Documents seen\",   ylab=\"Relevant  documents seen\",   xlim=c(0,nrow(df)) ) p <- calculate_h0(df) p #> [1] 0.8418202 df$seen <- 0 df$seen[1:30000] <- 1 plot(   cumsum(df[df$seen==1,\"relevant\"]),   type='l',   main=\"Simulation of ML-prioritised screening\",   xlab=\"Documents seen\",   ylab=\"Relevant  documents seen\",   xlim=c(0,nrow(df)) ) p <- calculate_h0(df) p #> [1] 0.01742366"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"changing-recall-targets","dir":"Articles","previous_headings":"","what":"Changing recall targets","title":"Stopping Criteria","text":"can calculate stopping criteria different recall target, simply using recall_target argument calculate_h0. increase recall target, become less confident missed target. many practical cases, may confident one target, much confident target little smaller. recall_frontier function calculates plots p score several different recall targets, helping inform transparently communicate decision safety stopping screening given point.  also returns dataframe p score different recall targets","code":"p <- calculate_h0(df, recall_target=0.99) p #> [1] 0.5991158 recall_df <- recall_frontier(df) #> Warning in phyper(k_vec, k_hat_vec, red_ball_vec, n_vec): NaNs produced  #> Warning in phyper(k_vec, k_hat_vec, red_ball_vec, n_vec): NaNs produced head(recall_df) #>   target p #> 1  0.010 0 #> 2  0.015 0 #> 3  0.020 0 #> 4  0.025 0 #> 5  0.030 0 #> 6  0.035 0"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"retrospective-stopping-criteria","dir":"Articles","previous_headings":"","what":"Retrospective stopping criteria","title":"Stopping Criteria","text":"package also includes helper function calculate stopping criteria point curve already seen. default calculate batch 1,000 documents. Change batch_size alter , though warned reducing increase number calculations needs made.  well making plot, also return dataframe p score batch","code":"h0_df <- retrospective_h0(df)"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"biased-urns","dir":"Articles","previous_headings":"","what":"Biased urns","title":"Stopping Criteria","text":"stopping criteria, described Callaghan Müller-Hansen (2020), assumes documents screened previously drawn random remaining records. assumption conservative, machine-learning process make likely pick relevant document irrelevant document. conservative, safe use stopping criteria (evaluations show wrong less 5% time confidence level set 95%), conservative nature means stop later strictly need . Biased urn theory offers us realistic set assumptions, describes probability distribution given situation likely select one type item another. can implement buscarR, setting bias parameter functions. bias describes much likely select relevant non-relevant document. However, estimating parameter non-trivial, work safely currently ongoing.","code":"h0_df1 <- retrospective_h0(df, bias=1, plot=FALSE) h0_df2 <- retrospective_h0(df, bias=5, plot=FALSE)  colors <- c(\"#8da0cb\",\"#fc8d62\")  matplot(   h0_df2$seen,    cbind(h0_df1$p,h0_df2$p),   main='p score for H0',   type='b',   ylab='p H0',   xlab='Documents seen',   col=colors,lty=c(1,1), pch=c(1,1) ) legend(500,0.2, legend=c(\"unbiased\",\"biased\"),col=colors,lty=c(1,1))"},{"path":"https://mcallaghan.github.io/buscarR/articles/stopping-criteria.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Stopping Criteria","text":"use stopping criteria work, please cite Callaghan Müller-Hansen (2020)","code":""},{"path":"https://mcallaghan.github.io/buscarR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Max Callaghan. Maintainer.","code":""},{"path":"https://mcallaghan.github.io/buscarR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Callaghan, M.W., Müller-Hansen, F. Statistical stopping criteria automated screening systematic reviews. Syst Rev 9, 273 (2020). https://doi.org/10.1186/s13643-020-01521-4","code":"@Article{,   title = {Statistical Stopping Criteria for Automated Screening in Systematic Reviews},   author = {Max Callaghan},   journal = {Systematic Reviews},   year = {2020},   volume = {9},   number = {273},   url = {https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-020-01521-4}, }"},{"path":"https://mcallaghan.github.io/buscarR/index.html","id":"buscarr","dir":"","previous_headings":"","what":"Calculates reliable stopping criteria for users of machine-learning prioritised screening in systematic reviews","title":"Calculates reliable stopping criteria for users of machine-learning prioritised screening in systematic reviews","text":"BuscarR, short Biased Urn based Stopping Criteria technology Assisted Review R, package implementing stopping criteria described Callaghan, Max, Finn Müller-Hansen. 2020. “Statistical Stopping Criteria Automated Screening Systematic Reviews.” Systematic Reviews, September. https://doi.org/10.21203/rs.2.18218/v2. stopping criteria offers reliable method decide stop screening machine learning-prioritised screening systematic review, document review ediscovery. method vital order use machine learning safely (estimating risk missing documents). method describes statistical confidence levels given level recall achieved. , offers robust data-driven method decide stop, clear transparent way communicating risks stopping given point. Read vignette(\"stopping-criteria\") details works package, check original paper full description criteria, including theory evaluations.","code":""},{"path":"https://mcallaghan.github.io/buscarR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Calculates reliable stopping criteria for users of machine-learning prioritised screening in systematic reviews","text":"","code":"# Install development version from GitHub devtools::install_github(\"mcallaghan/buscarR\")"},{"path":"https://mcallaghan.github.io/buscarR/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Calculates reliable stopping criteria for users of machine-learning prioritised screening in systematic reviews","text":"BuscarR requires dataframe row document query, two columns: relevant, seen. relevant contain 1, documents included human, 0 excluded human. documents yet screened NA. documents screened human contain 1 seen column, documents yet seen human contain 0. get p-score null hypothesis given recall target missed, use calculate_h0 function dataset. p score 1 minus confidence level, can reject null hypothesis target missed, stop screening. vignette(\"stopping-criteria\") contains examples, explanations, additional functions.","code":"library(buscarR) calculate_h0(df, recall_target=0.95)"},{"path":"https://mcallaghan.github.io/buscarR/reference/calculate_h0.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate h0 — calculate_h0","title":"Calculate h0 — calculate_h0","text":"Calculates p-score null hypothesis h0, missed recall target `recall_target`.","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/calculate_h0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate h0 — calculate_h0","text":"","code":"calculate_h0(df, recall_target = 0.95, bias = 1, seen_docs = NULL)"},{"path":"https://mcallaghan.github.io/buscarR/reference/calculate_h0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate h0 — calculate_h0","text":"df data.frame contains columns `relevant` `seen` dataframe many rows documents, ordered order dictated ML prioritisation algorithm. relevant contain 1s 0s relevant irrelevant documents, NAs documents yet screened. Seen contain 1s documents screened human, 0s documents yet screened recall_target recall target (default=0.95). Must 0 1 bias number represents estimate much likely select random relevant document random irrelevant document. higher , better think machine learning went. seen_docs integer overrides seen column, telling us many first documents screened","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/calculate_h0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate h0 — calculate_h0","text":"p, p-score null hypothesis. can reject null hypothesis (stop screening) p 1 - confidence level.","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/calculate_h0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate h0 — calculate_h0","text":"","code":"N <- 60000 # number of documents prevalence <- 0.01 # prevalence of relevant documents r <- N*0.01 # number of relevant documents bias <- 10 docs <- rep(0,N) docs[1:r] <- 1 weights = rep(1,N) weights[1:r] <- bias set.seed(2023) docs <- sample(   docs, prob=weights, replace=F ) df <- data.frame(relevant=docs) df$seen <- 0 df$seen[1:1000] <- 1 calculate_h0(df) #> [1] 0.9996611"},{"path":"https://mcallaghan.github.io/buscarR/reference/k_h0.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate K for H0 — k_h0","title":"Calculate K for H0 — k_h0","text":"`k_h0` calculates smallest number relevant documents urn, us missed given recall target","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/k_h0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate K for H0 — k_h0","text":"","code":"k_h0(r_al, r_seen, recall_target)"},{"path":"https://mcallaghan.github.io/buscarR/reference/k_h0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate K for H0 — k_h0","text":"r_al number relevant documents seen drawing urn began r_seen total number relevant documents seen. recall_target recall target.","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/k_h0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate K for H0 — k_h0","text":"k smallest integer compatible null hypothesis","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/recall_frontier.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate recall frontier — recall_frontier","title":"Calculate recall frontier — recall_frontier","text":"Calculates p scores across different recall targets","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/recall_frontier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate recall frontier — recall_frontier","text":"","code":"recall_frontier(df, bias = 1)"},{"path":"https://mcallaghan.github.io/buscarR/reference/recall_frontier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate recall frontier — recall_frontier","text":"df data.frame contains columns `relevant` `seen` dataframe many rows documents, ordered order dictated ML prioritisation algorithm. relevant contain 1s 0s relevant irrelevant documents, NAs documents yet screened. Seen contain 1s documents screened human, 0s documents yet screened bias number represents estimate much likely select random relevant document random irrelevant document. higher , better think machine learning went. plot Boolean describing whether plot graph (default=True).","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/recall_frontier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate recall frontier — recall_frontier","text":"dataframe column `p` showing p score h0 calculated given recall target `target`","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/recall_frontier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate recall frontier — recall_frontier","text":"","code":"N <- 60000 # number of documents prevalence <- 0.01 # prevalence of relevant documents r <- N*0.01 # number of relevant documents bias <- 10 docs <- rep(0,N) docs[1:r] <- 1 weights = rep(1,N) weights[1:r] <- bias set.seed(2023) docs <- sample(   docs, prob=weights, replace=F ) df <- data.frame(relevant=docs) df$seen <- 0 df$seen[1:20000] <- 1 recall_df <- recall_frontier(df) #> Warning: NaNs produced"},{"path":"https://mcallaghan.github.io/buscarR/reference/retrospective_h0.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate retrospective H0 — retrospective_h0","title":"Calculate retrospective H0 — retrospective_h0","text":"Calculates p scores null hypothesis H0, every `batch_size` documents documents already screened, plot graph p scores, alongside curve showing number relevant documents identified.","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/retrospective_h0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate retrospective H0 — retrospective_h0","text":"","code":"retrospective_h0(   df,   recall_target = 0.95,   bias = 1,   batch_size = 1000,   plot = TRUE )"},{"path":"https://mcallaghan.github.io/buscarR/reference/retrospective_h0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate retrospective H0 — retrospective_h0","text":"df data.frame contains columns `relevant` `seen` dataframe many rows documents, ordered order dictated ML prioritisation algorithm. relevant contain 1s 0s relevant irrelevant documents, NAs documents yet screened. Seen contain 1s documents screened human, 0s documents yet screened recall_target recall target (default=0.95). Must 0 1 bias number represents estimate much likely select random relevant document random irrelevant document. higher , better think machine learning went. batch_size p score calculated every `batch_size` documents. Smaller batches result greater granularity larger computation time (default=1000). plot Boolean describing whether plot graph (default=True).","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/retrospective_h0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate retrospective H0 — retrospective_h0","text":"dataframe column `p` showing p score h0 calculated number screened documents column `seen`","code":""},{"path":"https://mcallaghan.github.io/buscarR/reference/retrospective_h0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate retrospective H0 — retrospective_h0","text":"","code":"N <- 60000 # number of documents prevalence <- 0.01 # prevalence of relevant documents r <- N*0.01 # number of relevant documents bias <- 10 docs <- rep(0,N) docs[1:r] <- 1 weights = rep(1,N) weights[1:r] <- bias set.seed(2023) docs <- sample(   docs, prob=weights, replace=F ) df <- data.frame(relevant=docs) df$seen <- 0 df$seen[1:30000] <- 1 h0_df <- retrospective_h0(df)"}]
